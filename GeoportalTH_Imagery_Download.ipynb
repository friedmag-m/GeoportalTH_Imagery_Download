{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################\n",
    "# GEO419 Projekt Nr. 2\n",
    "# Download of Imagery from the Thuringian Geoportal\n",
    "# Marcel Felix & Friederike Metz\n",
    "# from Sept. 2021 to Feb. 2022\n",
    "########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Download URL original\n",
    "## Höhendaten:\n",
    "# https://geoportal.geoportal-th.de/hoehendaten/DGM/dgm_2014-2019/dgm1_682_5644_1_th_2014-2019.zip?type=dhm1&id=16541&log=682_5644_1x1km&url=%2Fhoehendaten%2FDGM%2Fdgm_2014-2019%2Fdgm1_682_5644_1_th_2014-2019.zip\n",
    "## Orthophotos:\n",
    "# https://geoportal.geoportal-th.de/gaialight-th/_apps/dladownload/download.php?type=op&id=255133&log=202005-32682_5644\n",
    "\n",
    "### Gekürzt\n",
    "## Höhendaten:\n",
    "# DGM\n",
    "# https://geoportal.geoportal-th.de/hoehendaten/DGM/dgm_2014-2019/dgm1_682_5644_1_th_2014-2019.zip\n",
    "# DOM\n",
    "# https://geoportal.geoportal-th.de/hoehendaten/DOM/dom_2014-2019/dom1_682_5644_1_th_2014-2019.zip\n",
    "# LAS\n",
    "# https://geoportal.geoportal-th.de/hoehendaten/LAS/las_2014-2019/las_682_5644_1_th_2014-2019.zip+\n",
    "## Orthophotos:\n",
    "# https://geoportal.geoportal-th.de/gaialight-th/_apps/dladownload/download.php?type=op&id=255133\n",
    "# filename: dop20rgbi_32_641_5656_1_th_2020.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ID Kachelbenennung\n",
    "## Höhendaten: \n",
    "# 682_5644 -> 682 steht für die West-Ost-Ausrichtung (nach Osten aufsteigend)\n",
    "# 682_5644 -> 5644 steht für die Nord-Süd-Ausrichtung (nach Norden aufsteigend)\n",
    "\n",
    "# Die Kacheln (Position) für Höhendaten und Orthophotos sind identisch\n",
    "# ...das bedeutet man kann identifizieren, welche Kacheln der Orthophotos gebraucht werden \n",
    "# ...ohne ihre ID vorher zu kennen. Stattdessen muss man sie berechnen:\n",
    "\n",
    "## Orthophotos:\n",
    "# 255133 -> 255 steht für ???\n",
    "# 255133 -> 133 steht für ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Importblock\n",
    "import os\n",
    "#import gdal\n",
    "import re\n",
    "from osgeo import ogr,osr,gdal\n",
    "import geopandas\n",
    "import shapely\n",
    "import zipfile\n",
    "from shapely.geometry import Polygon, LineString, Point\n",
    "import requests\n",
    "import ipyleaflet as ip\n",
    "from ipywidgets import Layout\n",
    "from joblib import Parallel, delayed\n",
    "# import time\n",
    "import pandas as pd\n",
    "import utm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### User's choices ###############\n",
    "##################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Please select your shapefile here\n",
    "shapefile = \"F:/Marcel/Backup/Dokumente/Studium/Geoinformatik/SoSe 2021/GEO419/Abschlussaufgabe/Data/shape/shape.shp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Please choose your dem-years (2010-2013 / 2014-2019 / 2020-2025)\n",
    "dem_year = \"2014-2019\"\n",
    "\n",
    "if dem_year == \"2010-2013\":\n",
    "    request = \"https://geoportal.geoportal-th.de/hoehendaten/Uebersichten/Stand_2010-2013.zip\"\n",
    "if dem_year == \"2014-2019\":\n",
    "    request = \"https://geoportal.geoportal-th.de/hoehendaten/Uebersichten/Stand_2014-2019.zip\"\n",
    "if dem_year == \"2020-2025\":\n",
    "    request = \"https://geoportal.geoportal-th.de/hoehendaten/Uebersichten/Stand_2020-2025.zip\"\n",
    "    # ^These are the download-links for the dem tile polygons\n",
    "# and your Orthophoto year\n",
    "year = \"2019\"\n",
    "    # unique years are: 1997, 2008, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automated DOWNLOAD OF TILE POLYGONS\n",
    "if os.path.exists(\"../Data/Stand_\"+dem_year) == False:\n",
    "    os.mkdir(\"../Data/Stand_\"+dem_year)\n",
    "\n",
    "gridfile = \"../Data/Stand_\"+dem_year+\"/Stand_\"+dem_year+\".zip\"\n",
    "\n",
    "if os.path.exists(gridfile) == False:\n",
    "    grid_polygons = requests.get(request)\n",
    "    with open(gridfile, \"wb\") as file:\n",
    "            file.write(grid_polygons.content)\n",
    "\n",
    "with zipfile.ZipFile(gridfile, 'r') as zip_ref:\n",
    "    zip_ref.extractall(\"../Data/Stand_\"+dem_year)\n",
    "os.remove(gridfile)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Please choose your desired file format (dgm / dom / las)\n",
    "dem_format = \"dgm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['680_5643', '680_5644', '681_5643', '681_5644']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "### File choices ###############\n",
    "################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Intersection of shapefile with dem tile polygons\n",
    "polygon = geopandas.read_file(shapefile)\n",
    "if dem_year == \"2010-2013\":\n",
    "    grid_path = \"../Data/Stand_2010-2013/DGM2_2010-2013_Erfass-lt-Meta_UTM32-UTM_2014-12-10.shp\"\n",
    "elif dem_year == \"2014-2019\":\n",
    "    grid_path = \"../Data/Stand_2014-2019/DGM1_2014-2019_Erfass-lt-Meta_UTM_2020-04-20--17127.shp\"\n",
    "else:\n",
    "    grid_path = \"../Data/Stand_2020-2025/DGM1_2020-2025_Erfass-lt-Meta_UTM_2021-03--17127.shp\"\n",
    "    \n",
    "grid = geopandas.read_file(grid_path)\n",
    "\n",
    "tiles = []\n",
    "for poly in grid.iterrows():\n",
    "    geom = poly[1].geometry\n",
    "    for poly2 in polygon.iterrows():\n",
    "        geom2 = poly2[1].geometry\n",
    "        \n",
    "        if geom.overlaps(geom2) == True:\n",
    "            tiles.append(poly[1].NAME)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. dem tile names\n",
    "tiles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Identifying op tile names\n",
    "def OP_Tilename_Finder(request:str, index:int):\n",
    "    \"\"\"Request function which returns ID and filename;\n",
    "    requires the request url and an ID to query\n",
    "    \"\"\"\n",
    "    r = requests.head(request) \n",
    "    try:\n",
    "        text = r.headers[\"Content-disposition\"]\n",
    "    except KeyError: return\n",
    "    \n",
    "    filename = text.split(\"=\")[1].replace('\"', '')\n",
    "    if \"dop\" in filename:\n",
    "        return [index, filename]\n",
    "    else: return\n",
    "\n",
    "def Start_after_Interruption(n_jobs:int = 200, end:int = 300000):\n",
    "    \"\"\"If the execution has been interrupted you can launch the process from here\n",
    "        This will read the last ID in the created list and continue from there, \n",
    "        to an end that you have to set\"\"\"\n",
    "    # location of ipynb\n",
    "    os.chdir(\"F:/Marcel/Backup/Dokumente/Studium/Geoinformatik/SoSe 2021/GEO419/Abschlussaufgabe/GeoportalTH_Imagery_Download/\")\n",
    "    \n",
    "    idfile = \"../Data/\"+\"idlist.txt\"    #created list\n",
    "    with open(idfile, \"r\") as file:\n",
    "        last = int(file.readlines()[-1].split(\",\")[0])+1 #extracts last ID and sets it +1\n",
    "    if last >= end:\n",
    "        return(\"End already reached\")\n",
    "    OP_Tilelist_Creator(n_jobs, last, end)\n",
    "        \n",
    "def OP_Tilelist_Creator(n_jobs:int = 200, start:int = 100000, end:int = 300000):\n",
    "    \"\"\"Function for complete query of all tile IDs on the server within a specified range\n",
    "    \n",
    "    Defining query parameters in function call:\n",
    "         -- n_jobs # based on empirical testing, determines the number of threads/requests \n",
    "         -- first ID\n",
    "         -- last ID\n",
    "         \"\"\"\n",
    "    # location of ipynb\n",
    "    os.chdir(\"F:/Marcel/Backup/Dokumente/Studium/Geoinformatik/SoSe 2021/GEO419/Abschlussaufgabe/GeoportalTH_Imagery_Download/\")\n",
    "    \n",
    "    #create file in advance\n",
    "    idfile = \"../Data/\"+\"idlist.txt\" #location of file to be created\n",
    "    if os.path.exists(idfile) == False:\n",
    "        with open(idfile, \"w\") as file:\n",
    "            file.write(\"id,filename\\n\")\n",
    "    \n",
    "    \n",
    "    #requesting loop\n",
    "    # end = start + n_jobs*2 # only for testing \n",
    "    for current in range(start, end, n_jobs): \n",
    "        with Parallel(n_jobs, require=\"sharedmem\", prefer=\"threads\") as parallel:\n",
    "            names_list = parallel(delayed(OP_Tilename_Finder)(\"https://geoportal.geoportal-th.de/gaialight-th/_apps/dladownload/download.php?type=op&id=\"+str(index), index) for index in range(current, current+n_jobs))\n",
    "                # will extend beyond \"end\" and secure that none are left out\n",
    "        with open(idfile, \"a+\") as file:\n",
    "            for entry in names_list:\n",
    "                if entry != None:\n",
    "                    file.write(str(entry[0]) + \",\" + entry[1] + \"\\n\")\n",
    "    return # names_list #for checking "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OP_Tilelist_Creator()\n",
    "# only when no list available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Download request ###\n",
    "########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tiles' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-8d1e4c890717>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m### Download request\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# 7. Download of dem tiles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mtile\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtiles\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[1;31m# creating request url\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdem_format\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"dgm\"\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mdem_format\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"dom\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tiles' is not defined"
     ]
    }
   ],
   "source": [
    "# 7. Download of dem tiles\n",
    "for tile in tiles:\n",
    "    # creating request url\n",
    "    if dem_format == \"dgm\" or dem_format == \"dom\":\n",
    "        request = \"https://geoportal.geoportal-th.de/hoehendaten/\"+dem_format.upper()+\"/\"+dem_format+\"_\"+dem_year+\"/\"+dem_format+\"1_\"+tile+\"_1_th_\"+dem_year+\".zip\"\n",
    "    elif dem_format == \"las\": \n",
    "        request = \"https://geoportal.geoportal-th.de/hoehendaten/\"+dem_format.upper()+\"/\"+dem_format+\"_\"+dem_year+\"/\"+dem_format+\"_\"+tile+\"_1_th_\"+dem_year+\".zip+\"\n",
    "    \n",
    "    dem_load = requests.get(request)\n",
    "    # download the file to data folder\n",
    "    current_dem = \"../Data/dem/\"+tile+\".zip\"\n",
    "    demzip = []\n",
    "    demzip.append(current_dem)\n",
    "    with open(current_dem, \"wb\") as file:\n",
    "        file.write(dem_load.content)\n",
    "        \n",
    "    # unzipping\n",
    "    with zipfile.ZipFile(current_dem, 'r') as zip_ref:\n",
    "        zip_ref.extractall(\"../Data/dem/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Download of op tiles\n",
    "# create data from lookup file\n",
    "lookup = pd.read_csv(idfile, header=0, delimiter=',')\n",
    "# unique years are: 1997, 2008, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020\n",
    "\n",
    "idlist = []\n",
    "\n",
    "# filter lookup table by year\n",
    "lookup = lookup[lookup[\"year\"] == year]\n",
    "\n",
    "# tiles from 2018 and earlier are grouped in four; only even numbers for x and y are registered with an ID\n",
    "# therefore we need to make sure, we catch all the tiles inbetween \n",
    "# only the lower left tile out of the four (where x&y are even) has an ID\n",
    "if year <= 2018:\n",
    "    tiles_check = tiles.copy()      # a copy to iterate over while the original is being altered\n",
    "    for tile in tiles_check:\n",
    "        tile_x, tile_y = tile.split(\"_\")\n",
    "        tile_x, tile_y = int(tile_x), int(tile_y)\n",
    "        \n",
    "        if ((tile_x & 1) + (tile_y & 1)) == 1:              # if either x or y is uneven, then correct their coordinates to find the matching ID\n",
    "            if tile_x & 1 == 1:\n",
    "                tile_x, tile_y = str(tile_x-1), str(tile_y)\n",
    "            elif tile_y & 1 == 1:\n",
    "                tile_y, tile_x = str(tile_y-1), str(tile_x)\n",
    "                \n",
    "        elif (tile_x & 1) + (tile_y & 1) == 2:              # if both are uneven\n",
    "            tile_x, tile_y = str(tile_x-1), str(tile_y-1)\n",
    "        \n",
    "        else: continue\n",
    "        \n",
    "        # first make sure, the \"wrong\" tile is dropped from list    \n",
    "        tiles.remove(tile)  \n",
    "        # at last, append the newly found tile back into the list\n",
    "        new_tile = tile_x + \"_\" + tile_y\n",
    "        if not new_tile in tiles:  # but only if it's not already there!\n",
    "            tiles.append(new_tile)\n",
    "\n",
    "# now find the matching IDs\n",
    "for tile in tiles:\n",
    "    tile_match = lookup[lookup[\"tilename\"] == tile]\n",
    "    id_match = tile_match.values[0][0] # first row, first column\n",
    "    idlist.append(id_match)\n",
    "\n",
    "# download the identified files\n",
    "for tile_id in idlist:\n",
    "    # create dir if necessary\n",
    "    if os.path.exists(\"../Data/op/\") == False:\n",
    "        os.mkdir(\"../Data/op/\")\n",
    "    \n",
    "    # download the file\n",
    "    current_op = \"../Data/op/\" + str(tile_id) + \".zip\"\n",
    "    # if already there, unzip and then continue with the next tile\n",
    "    if os.path.exists(current_op):\n",
    "        with zipfile.ZipFile(current_op, 'r') as zip_ref:\n",
    "            zip_ref.extractall(\"../Data/op/\")\n",
    "        continue\n",
    "    \n",
    "    op_load = requests.get(\"https://geoportal.geoportal-th.de/gaialight-th/_apps/dladownload/download.php?type=op&id=\" + str(tile_id))\n",
    "    op_zip = []\n",
    "    op_zip.append(current_op)\n",
    "    \n",
    "    # safe to file\n",
    "    with open(current_op, \"wb\") as file:\n",
    "        file.write(op_load.content)\n",
    "\n",
    "    with zipfile.ZipFile(current_op, 'r') as zip_ref:\n",
    "        zip_ref.extractall(\"../Data/op/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### Converting XYZ to tif and Merging DEMs and OP ###\n",
    "#####################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. Conversion & Merge of DEM\n",
    "\n",
    "# find the DEM xyz files\n",
    "demlist = []\n",
    "for file in os.scandir(\"../Data/dem/\"):\n",
    "    if file.name.endswith(\".xyz\"):\n",
    "        demlist.append(file.path)\n",
    "\n",
    "# convert to tif\n",
    "for xyz in demlist:\n",
    "    outname = xyz.replace(\".xyz\",\"\")\n",
    "    gdal.Translate(outname + \".tif\", xyz, outputSRS=\"EPSG:25832\")\n",
    "\n",
    "# merging of DEMs\n",
    "# build virtual raster and convert to geotiff\n",
    "demlist = [file.replace(\".xyz\",\".tif\") for file in demlist]\n",
    "vrt = gdal.BuildVRT(\"../Data/dem/merged.vrt\", demlist)\n",
    "gdal.Translate(\"../Data/dem/mergedDEM.tif\", vrt, xRes = 1, yRes = -1)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10.Merge of OP\n",
    "\n",
    "# find the OP files\n",
    "oplist = []\n",
    "for file in os.scandir(\"../Data/op/\"):\n",
    "    if file.name.endswith(\".tif\"):\n",
    "        oplist.append(file.path)\n",
    "\n",
    "# merging of OPs\n",
    "vrt = gdal.BuildVRT(\"../Data/dem/merged.vrt\", oplist)\n",
    "gdal.Translate(\"../Data/op/mergedOP.tif\", vrt, xRes = 0.2, yRes = -0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### Clipping all to custom extent ###\n",
    "####################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. clipping with shapefile\n",
    "\n",
    "inraster = \"../Data/op/mergedOP.tif\"\n",
    "clipraster = \"../Data/op/mergedOP_clip.tif\"\n",
    "options = {\"cutlineDSName\":shapefile, \"cropToCutline\":True, \"dstNodata\":0, \"dstSRS\":\"EPSG:25832\"}\n",
    "result = gdal.Warp(clipraster, inraster, **options)\n",
    "result = None\n",
    "\n",
    "inraster = \"../Data/dem/mergedDEM.tif\"\n",
    "clipraster = \"../Data/dem/mergedDEM_clip.tif\"\n",
    "options = {\"cutlineDSName\":shapefile, \"cropToCutline\":True, \"dstNodata\":0, \"dstSRS\":\"EPSG:25832\"}\n",
    "result = gdal.Warp(clipraster, inraster, **options)\n",
    "result = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Visualisation ###\n",
    "#####################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 12. initialize map and load open street map\n",
    "\n",
    "# convert AOI centroid utm to latlon\n",
    "centering = utm.to_latlon(polygon.centroid.x[0], polygon.centroid.y[0], 32, 'U')\n",
    "\n",
    "# add a OSM basemap\n",
    "map = ip.Map(basemap = ip.basemaps.CartoDB.Positron, center = (centering[0], centering[1]), \n",
    "             zoom = 12, layout = Layout(width = '100%', height = '700px'))\n",
    "\n",
    "wms = ip.WMSLayer(url = 'https://tile.openstreetmap.org/${z}/${x}/${y}.png', format = 'image/png', transparent = True)\n",
    "map.add_layer(wms)\n",
    "\n",
    "# add a marker\n",
    "map_marker = ip.Marker(location=(centering[0], centering[1]))\n",
    "map.add_layer(map_marker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13. overlay Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding the AOI polygon \n",
    "map_poly = polygon.to_crs(4326)\n",
    "map_polygon = ip.GeoData(geo_dataframe = map_poly,\n",
    "                   style = {'color': 'black', 'fillColor': '#3366cc', 'opacity':0.4, 'weight':1.9, 'dashArray':'2', 'fillOpacity':0.05},\n",
    "                   hover_style = {'fillColor': 'red' , 'fillOpacity': 0.05},\n",
    "                   name = 'AOE')\n",
    "map.add_layer(map_polygon)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<osgeo.gdal.Dataset; proxy of <Swig Object of type 'GDALDatasetShadow *' at 0x0000021F1027D9C0> >"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create OP and DEM layers to show\n",
    "\n",
    "gdal.Translate(\"../Data/op/mergedOP_clip.png\", \"../Data/op/mergedOP_clip.tif\", outputSRS=\"EPSG:4326\")\n",
    "gdal.Translate(\"../Data/dem/mergedDEM_clip.png\", \"../Data/dem/mergedDEM_clip.tif\", outputSRS=\"EPSG:4326\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding an OP layer\n",
    "\n",
    "op_raster = ip.ImageOverlay(\n",
    "    url = \"http://localhost:8888/tree/Abschlussaufgabe/Data/op/mergedOP_clip.png\", #adjust url if necessary\n",
    "    bounds = ((map_poly.bounds.miny[0], map_poly.bounds.minx[0]) , (map_poly.bounds.maxy[0],map_poly.bounds.maxx[0])) #low left & upper right\n",
    ")\n",
    "map.add_layer(op_raster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding an DEM layer\n",
    "\n",
    "dem_raster = ip.ImageOverlay(\n",
    "    url = \"http://localhost:8888/tree/Abschlussaufgabe/Data/dem/mergedDEM_clip.png\", #adjust url if necessary\n",
    "    bounds = ((map_poly.bounds.miny[0], map_poly.bounds.minx[0]) , (map_poly.bounds.maxy[0],map_poly.bounds.maxx[0])) #low left & upper right\n",
    ")\n",
    "map.add_layer(dem_raster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1603997bb62742c8955a9152c52adfca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[50.92066794243591, 11.575571121873141], controls=(ZoomControl(options=['position', 'zoom_in_text',…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#show Map\n",
    "map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
